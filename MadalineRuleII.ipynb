{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMmKNrChKwNzTZfQuplmf7O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pepetonof/UX-DL/blob/main/MadalineRuleII.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "bam-c6IM7akC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bipolar(x):\n",
        "    return np.where(x >= 0, 1, -1)"
      ],
      "metadata": {
        "id": "Xr211h6k7Z-g"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = 2\n",
        "hidden_size = 2\n",
        "output_size = 1\n",
        "\n",
        "X = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]]) # Valores de entrada\n",
        "D = np.array([-1, 1, 1, -1])  # Salida esperada XOR\n",
        "\n",
        "#pesos iniciales\n",
        "#np.random.seed(0)\n",
        "#W1 = np.array([[0.1, 0.2, -0.1],[0.3, -0.2, 0.2]])\n",
        "#W2 = np.array([[0.1, 0.3, -0.4]])\n",
        "#W1 = np.random.uniform(-1, 1, size = (hidden_size, input_size + 1))\n",
        "#W2 = np.random.uniform(-1, 1, size = (output_size, hidden_size + 1))\n"
      ],
      "metadata": {
        "id": "iSnW2rIi7rjE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class madaline:\n",
        "    def __init__(self, input_size, hidden_size, output_size, lr=0.2):\n",
        "        self.lr = lr\n",
        "        # Inicializar pesos para la capa oculta (se incluye el peso de bias)\n",
        "        #self.W1 = np.random.uniform(-1, 1, size = (hidden_size, input_size + 1))\n",
        "        # Inicializar pesos para la capa de salida (incluyendo el bias de la capa oculta)\n",
        "        #self.W2 = np.random.uniform(-1, 1, size = (output_size, hidden_size + 1))\n",
        "        #self.W1 = np.array([[0.1, 0.2, -0.1],[0.3, -0.2, 0.2]])\n",
        "        #self.W1 = np.array([[0.3, 0.0, 0.1],[0.3, -0.2, 0.2]])\n",
        "        self.W1 = np.array([[0.1, 0.2, 0.1],[0.3, -0.2, 0.2]])\n",
        "        #self.W2 = np.array([[0.3, 0.1, -0.6]])\n",
        "        #self.W2 = np.array([[0.3, 0.1, -0.6]])\n",
        "        self.W2 = np.array([[0.5, 0.3, -0.4]])\n",
        "    def forward(self, x):\n",
        "        if len(x.shape)==1:\n",
        "            x = x.reshape(1,x.shape[0])\n",
        "        rows = x.shape[0]\n",
        "        ext = np.ones((rows, 1))\n",
        "        if len(x.shape) == 1:\n",
        "            x = x.reshape(x.shape[0],1)\n",
        "        x_ext = np.hstack((ext,x))\n",
        "        self.hidden_input = np.dot(x_ext, self.W1.T)  # vector de tamaño (hidden_size,)\n",
        "        print('Entrada oculta', self.hidden_input)\n",
        "        self.hidden_output = bipolar(self.hidden_input)\n",
        "        print('Salida oculta', self.hidden_output)\n",
        "\n",
        "        ext = np.ones((self.hidden_output.shape[0], 1))\n",
        "        hidden_ext = np.hstack((ext,self.hidden_output))\n",
        "        self.final_input = np.dot(hidden_ext, self.W2.T)\n",
        "        print('Entrada final', self.final_input)\n",
        "        self.final_output = bipolar(self.final_input)\n",
        "        print('Salida final', self.final_output)\n",
        "        return self.final_output"
      ],
      "metadata": {
        "id": "yDKUQQolFdcA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=1\n",
        "model = madaline(input_size, hidden_size, output_size)\n",
        "output = model.forward(X[i])\n",
        "error = D[i] - output\n",
        "print('Error', error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upKwIRDJGTBq",
        "outputId": "1cda3775-3c93-4550-d12e-296dc46c56a0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrada oculta [[0.  0.7]]\n",
            "Salida oculta [[1 1]]\n",
            "Entrada final [[0.4]]\n",
            "Salida final [[1]]\n",
            "Error [[0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, X, D, epochs=10):\n",
        "    for epoch in range(epochs):\n",
        "        errores = 0\n",
        "        for i in range(len(X)):\n",
        "            x = X[i]\n",
        "            print(x, x.shape)\n",
        "            x = x.reshape(1, x.shape[0])\n",
        "            print(x, x.shape)\n",
        "            rows = x.shape[0]\n",
        "            ext = np.ones((rows, 1))\n",
        "            x_ext = np.hstack((x, ext))\n",
        "            d = D[i]\n",
        "            print(x_ext)\n",
        "            y = model.forward(x_ext)\n",
        "            error = d - y\n",
        "\n",
        "            print(y, d)\n",
        "\n",
        "            # Si la salida es incorrecta, aplicar la Regla MRII\n",
        "            if error != 0:\n",
        "                errores += 1\n",
        "                # Seleccionar la neurona de la capa oculta con el nivel de confianza (valor absoluto del input)\n",
        "                # más cercano a cero (la menos segura)\n",
        "                min_index = np.argmin(np.abs(model.hidden_input))\n",
        "                # Se agrega el bias a la entrada\n",
        "                x_bias = np.insert(x, 0, 1)\n",
        "                # Determinar el signo del ajuste: se busca invertir la salida de la neurona seleccionada\n",
        "                delta = -np.sign(model.hidden_input[min_index]) if model.hidden_input[min_index] != 0 else 1\n",
        "                # Actualizar los pesos de la neurona seleccionada en la capa oculta\n",
        "                model.W1[min_index] += model.lr * delta * x_bias\n",
        "                # Se vuelve a propagar la entrada para evaluar el cambio\n",
        "                y_new = model.forward(x)\n",
        "                # Si el error persiste, se actualizan los pesos de la capa de salida\n",
        "                if y_new != d:\n",
        "                    # Agregar bias a la salida oculta\n",
        "                    hidden_bias = np.insert(model.hidden_output, 0, 1)\n",
        "                    # Actualizar los pesos de la capa de salida usando una regla simple\n",
        "                    model.W2 += model.lr * (d - y_new) * hidden_bias\n",
        "        # Si en una época no se detectan errores, se ha alcanzado la convergencia\n",
        "        if errores == 0:\n",
        "            print(f\"Convergencia alcanzada en la época {epoch+1}\")\n",
        "            break"
      ],
      "metadata": {
        "id": "zB5ptZicNKqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9tHq7CGVKmX",
        "outputId": "96f22d7b-2bdb-4cf1-a9a1-05cd2ab068cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultados para la compuerta XOR:\n",
            "Entrada: [-1 -1], Salida: [1]\n",
            "Entrada: [-1  1], Salida: [1]\n",
            "Entrada: [ 1 -1], Salida: [-1]\n",
            "Entrada: [1 1], Salida: [-1]\n"
          ]
        }
      ],
      "source": [
        "#Biblioteca numpy\n",
        "import numpy as np\n",
        "\n",
        "# Función de activación: hard-limiting\n",
        "def hardlims(x):\n",
        "    return np.where(x >= 0, 1, -1)\n",
        "\n",
        "# Clase que implementa una red MADALINE con MRII para la compuerta XOR\n",
        "class MadalineMRII:\n",
        "    def __init__(self, input_size, hidden_size, output_size, lr=0.2):\n",
        "        self.lr = lr\n",
        "        # Inicializar pesos para la capa oculta (se incluye el peso de bias)\n",
        "        self.W1 = np.random.uniform(-1, 1, (hidden_size, input_size + 1))\n",
        "        # Inicializar pesos para la capa de salida (incluyendo el bias de la capa oculta)\n",
        "        self.W2 = np.random.uniform(-1, 1, (output_size, hidden_size + 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: vector de entrada de tamaño (input_size,)\n",
        "        # Se añade el bias (valor 1) a la entrada\n",
        "        x_bias = np.insert(x, 0, 1)\n",
        "        # Cálculo de la entrada de la capa oculta\n",
        "        self.hidden_input = np.dot(self.W1, x_bias)  # vector de tamaño (hidden_size,)\n",
        "        # Salida de la capa oculta usando la función hardlims\n",
        "        self.hidden_output = hardlims(self.hidden_input)\n",
        "        # Añadir bias a la salida oculta\n",
        "        hidden_bias = np.insert(self.hidden_output, 0, 1)\n",
        "        # Cálculo de la entrada a la capa de salida\n",
        "        self.final_input = np.dot(self.W2, hidden_bias)\n",
        "        # Salida final de la red (también hardlims)\n",
        "        self.final_output = hardlims(self.final_input)\n",
        "        return self.final_output\n",
        "\n",
        "    def train(self, X, D, epochs=10000):\n",
        "        # X: matriz de entradas de tamaño (num_ejemplos, input_size)\n",
        "        # D: vector columna de salidas deseadas de tamaño (num_ejemplos, 1)\n",
        "        for epoch in range(epochs):\n",
        "            errores = 0\n",
        "            for i in range(len(X)):\n",
        "                x = X[i]\n",
        "                d = D[i]\n",
        "                y = self.forward(x)\n",
        "                error = d - y\n",
        "                # Si la salida es incorrecta, aplicar la Regla MRII\n",
        "                if error != 0:\n",
        "                    errores += 1\n",
        "                    # Seleccionar la neurona de la capa oculta con el nivel de confianza (valor absoluto del input)\n",
        "                    # más cercano a cero (la menos segura)\n",
        "                    min_index = np.argmin(np.abs(self.hidden_input))\n",
        "                    # Se agrega el bias a la entrada\n",
        "                    x_bias = np.insert(x, 0, 1)\n",
        "                    # Determinar el signo del ajuste: se busca invertir la salida de la neurona seleccionada\n",
        "                    delta = -np.sign(self.hidden_input[min_index]) if self.hidden_input[min_index] != 0 else 1\n",
        "                    # Actualizar los pesos de la neurona seleccionada en la capa oculta\n",
        "                    self.W1[min_index] += self.lr * delta * x_bias\n",
        "                    # Se vuelve a propagar la entrada para evaluar el cambio\n",
        "                    y_new = self.forward(x)\n",
        "                    # Si el error persiste, se actualizan los pesos de la capa de salida\n",
        "                    if y_new != d:\n",
        "                        # Agregar bias a la salida oculta\n",
        "                        hidden_bias = np.insert(self.hidden_output, 0, 1)\n",
        "                        # Actualizar los pesos de la capa de salida usando una regla simple\n",
        "                        self.W2 += self.lr * (d - y_new) * hidden_bias\n",
        "            # Si en una época no se detectan errores, se ha alcanzado la convergencia\n",
        "            if errores == 0:\n",
        "                print(f\"Convergencia alcanzada en la época {epoch+1}\")\n",
        "                break\n",
        "\n",
        "# Definir los datos de la compuerta XOR\n",
        "# Entradas: 2 neuronas\n",
        "X = np.array([\n",
        "    [-1, -1],\n",
        "    [-1,  1],\n",
        "    [ 1, -1],\n",
        "    [ 1,  1]\n",
        "])\n",
        "# Salidas deseadas: 1 neurona (usando la convención bipolar)\n",
        "D = np.array([\n",
        "    [-1],\n",
        "    [ 1],\n",
        "    [ 1],\n",
        "    [-1]\n",
        "])\n",
        "\n",
        "# Crear y entrenar el modelo\n",
        "model = MadalineMRII(input_size=2, hidden_size=2, output_size=1, lr=0.2)\n",
        "model.train(X, D, epochs=10000)\n",
        "\n",
        "# Prueba de la red entrenada\n",
        "print(\"Resultados para la compuerta XOR:\")\n",
        "for x in X:\n",
        "    output = model.forward(x)\n",
        "    print(f\"Entrada: {x}, Salida: {output}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.W1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbGhx_1J2sVs",
        "outputId": "b79bf8e2-8198-45bb-806e-f479ab37bccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.10237299,  0.63037873,  0.00552675],\n",
              "       [-0.11023363, -0.3526904 ,  0.09178823]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.W2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZQ6_LHt2xLF",
        "outputId": "a839ed6c-1893-48b9-885b-f14bf33a76d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.12482558, -0.016454  ,  0.12732552]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in X:\n",
        "    print(x.shape, x)\n",
        "    print(model.forward(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5TM2vgl42eJ",
        "outputId": "e6c9c69a-36bb-4f68-ecae-041a501fc28b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2,) [-1 -1]\n",
            "[1]\n",
            "(2,) [-1  1]\n",
            "[1]\n",
            "(2,) [ 1 -1]\n",
            "[-1]\n",
            "(2,) [1 1]\n",
            "[-1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.forward([-1,-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSCHjEfE5Dji",
        "outputId": "c403d875-3a28-4e7d-a0b3-03e24a84234e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "To7ViUOZ3cfF",
        "outputId": "57875bb8-9240-4299-fbf9-b020d845f384"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}